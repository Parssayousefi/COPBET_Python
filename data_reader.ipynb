{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import nibabel as nib\n",
    "from functions import CopBET_time_series_complexity\n",
    "\n",
    "\n",
    "def CopBET_CarhartHarris_2016_data(atlas='yeo7', ts_ROI2ROI='denoised_volumes', type='example'):\n",
    "    \"\"\"\n",
    "    Loads the CH2016 data structured according to the README file.\n",
    "    Args:\n",
    "        atlas (str, optional): Name of the atlas to use. Defaults to 'yeo7'.\n",
    "        ts_ROI2ROI (str, optional): Type of data ('denoised_volumes' or other). Defaults to 'denoised_volumes'.\n",
    "        type (str, optional): Whether to load 'full' dataset or 'example'. Defaults to 'example'. \n",
    "    Returns:\n",
    "        pandas.DataFrame: Dataframe containing metadata and file paths (or loaded data, if applicable).\n",
    "        list: Placeholder for data, if applicable.\n",
    "        dict: Placeholder for options, if relevant.\n",
    "    \"\"\"\n",
    "    possible_atlases = ['AAL90', 'Craddock200', 'HarvardOxford_cort_subcort', 'Lausanne463',\n",
    "                        'Schaefer1000', 'Shen268', 'yeo17', 'smith20', 'SchaeferTian232']\n",
    "    if atlas not in possible_atlases:\n",
    "        raise ValueError(f'Invalid atlas: {atlas}. Possible options: {possible_atlases}')\n",
    "    if type == 'example':\n",
    "        topfolder = os.path.join(os.getcwd(), 'LSDdata', 'exampledata')  # Path relative to current directory\n",
    "    elif type == 'full':\n",
    "        topfolder = os.path.join(os.getcwd(), 'LSDdata')\n",
    "    else:\n",
    "        raise ValueError(\"Please specify whether to load the full dataset ('full') or 'example'\")\n",
    "    subs = [d for d in os.listdir(topfolder) if os.path.isdir(os.path.join(topfolder, d)) and d.startswith('sub-')]\n",
    "    if not subs:\n",
    "        raise ValueError(\"No subject directories found. Check if you're in the right location.\")\n",
    "    conditions = ['ses-PLCB', 'ses-LSD']\n",
    "    opts = {'subjects': subs}  # Store subject names in opts\n",
    "    # Table initialization\n",
    "    tblvarnames = ['data', 'rp', 'subject', 'condition', 'session', 'num_vols', 'entropy']\n",
    "    tblvartypes = ['object', 'object', 'str', 'str', 'int', 'int', 'object']\n",
    "    tbl = pd.DataFrame(columns=tblvarnames)  # Create empty DataFrame \n",
    "    tblcount = 0\n",
    "    for sub in subs:\n",
    "        for cond in conditions:\n",
    "            for ses in [1, 3]:\n",
    "                sub_folder = os.path.join(topfolder, sub)\n",
    "                if ts_ROI2ROI == 'denoised_volumes':\n",
    "                    for potential_ext in ('.nii.gz', '_shortened.nii.gz'):\n",
    "                        file_path = os.path.join(sub_folder, cond, 'func', f\"{sub}_{cond}_task-rest_run-0{ses}_bold{potential_ext}\")\n",
    "                        if os.path.exists(file_path):\n",
    "                            tbl.loc[tblcount, 'data'] = file_path  # Use .loc for efficient assignment\n",
    "                            break\n",
    "                    else:\n",
    "                        raise FileNotFoundError(f\"Could not find denoised_volumes file for {sub}, {cond}, session {ses}\")\n",
    "                else:\n",
    "                    data_path = os.path.join(topfolder, 'ROIdata', atlas, f'{sub}_{cond}_task-rest_run-0{ses}_bold.mat')\n",
    "                    if os.path.exists(data_path):\n",
    "                        V_roi = loadmat(data_path)['V_roi']\n",
    "                        tbl.loc[tblcount, 'data'] = V_roi\n",
    "                        tbl.loc[tblcount, 'num_vols'] = V_roi.shape[0]\n",
    "                    else:\n",
    "                        raise FileNotFoundError(f\"Could not find ROI data file at {data_path}\")\n",
    "                tbl.loc[tblcount, 'subject'] = sub\n",
    "                tbl.loc[tblcount, 'condition'] = cond\n",
    "                tbl.loc[tblcount, 'session'] = ses\n",
    "                tblcount += 1\n",
    "    \n",
    "    # Equality Check\n",
    "    if ts_ROI2ROI != 'denoised_volumes':\n",
    "        for h in range(len(tbl)):  # Outer loop\n",
    "            for h2 in range(h + 1, len(tbl)):  # Inner loop; starts from h+1\n",
    "                if tbl['num_vols'][h] == tbl['num_vols'][h2]:  # Compare number of volumes\n",
    "                    data1 = tbl['data'][h]\n",
    "                    data2 = tbl['data'][h2]\n",
    "                    # Note: Assuming your tbl['data'] elements are NumPy arrays or similar\n",
    "                    if np.linalg.norm(data1 - data2, 'fro') < 1:  # Frobenius norm check\n",
    "                        error_msg = f\"Equality problem for {h}-{h2}\"\n",
    "                        raise ValueError(error_msg)\n",
    "\n",
    "    data = []  # Placeholder for any data you want to return\n",
    "\n",
    "    tbl['data'] = tbl['data'].apply(np.array)\n",
    "    return tbl, data, opts\n",
    "\n",
    "\n",
    "# GitHub Copilot\n",
    "# used /explain\n",
    "# The DataFrame created in the CopBET_CarhartHarris_2016_data function has the following structure:\n",
    "\n",
    "# The DataFrame has columns with the following names: 'data', 'rp', 'subject', 'condition', 'session', 'num_vols', and 'entropy'.\n",
    "# Each row of the DataFrame represents a specific data entry or observation.\n",
    "# The 'data' column stores the file path or loaded data, depending on the value of the ts_ROI2ROI parameter. If ts_ROI2ROI is set to 'denoised_volumes', the 'data' column contains the file path of the denoised volumes file. If ts_ROI2ROI is set to any other value, the 'data' column contains the loaded ROI data.\n",
    "# The 'rp' column is not used in the provided code and is left as an empty object.\n",
    "# The 'subject' column stores the subject name associated with the data entry.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tbl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtbl\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tbl' is not defined"
     ]
    }
   ],
   "source": [
    "tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Overwriting entropy column in data table\n",
      "Beginning entropy calculations\n",
      "Running LZ78spatial\n",
      "Type of input_data: <class 'pandas.core.frame.DataFrame'>\n",
      "Shape of input_data: (4, 7)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m tbl, data, opts \u001b[38;5;241m=\u001b[39m CopBET_CarhartHarris_2016_data(atlas, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdenoised_volumes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexample\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Calculate temporal complexity\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m tbl \u001b[38;5;241m=\u001b[39m \u001b[43mCopBET_time_series_complexity\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtbl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLZtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLZ78spatial\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m tbl[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime_series_complexity_temporal\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m tbl[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentropy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Plotting the temporal complexity\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#plot_boxplots_ch2016(tbl['entropy'], tbl, 'Time series complexity, temporal')\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Plotting the spatial complexity\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#plot_boxplots_ch2016(tbl['entropy'], tbl, 'Time series complexity, spatial')\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prsyu\\OneDrive\\Bidlung\\University\\M.S. Leiden University\\M.S. Neuroscience (Research)\\Thesis\\CopBET\\CopBET_Python\\functions.py:77\u001b[0m, in \u001b[0;36mCopBET_time_series_complexity\u001b[1;34m(input_data, LZtype, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(input_data, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of input_data list: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_data:\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType of first element in input_data: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(input_data[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(input_data[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\prsyu\\.conda\\envs\\nilearn\\lib\\site-packages\\pandas\\core\\generic.py:1576\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1574\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   1575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__nonzero__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[1;32m-> 1576\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe truth value of a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is ambiguous. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1578\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1579\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "\n",
    "# Varley script, temporal LZ78\n",
    "atlas = 'Schaefer1000'\n",
    "tbl, data, opts = CopBET_CarhartHarris_2016_data(atlas, 'denoised_volumes', 'example')\n",
    "\n",
    "# Calculate temporal complexity\n",
    "\n",
    "\n",
    "tbl = CopBET_time_series_complexity(input_data=tbl, LZtype='LZ78spatial', keepdata=False, parallel=True)\n",
    "\n",
    "tbl['Time_series_complexity_temporal'] = tbl['entropy']\n",
    "\n",
    "\n",
    "# Plotting the temporal complexity\n",
    "#plot_boxplots_ch2016(tbl['entropy'], tbl, 'Time series complexity, temporal')\n",
    "\n",
    "# Varley script, spatial LZ78\n",
    "#tbl, data, opts = CopBET_CarhartHarris_2016_data(atlas, 'ts', 'example')\n",
    "#tbl = CopBET_time_series_complexity(tbl, 'LZ78spatial', True, True)\n",
    "\n",
    "#tbl['Time_series_complexity_spatial'] = tbl['entropy']\n",
    "\n",
    "# Plotting the spatial complexity\n",
    "#plot_boxplots_ch2016(tbl['entropy'], tbl, 'Time series complexity, spatial')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nilearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
